# ARTransformerForecaster

## Описание

**ARTransformerForecaster** — это авто-регрессивная модель на базе Transformer Encoder для прогнозирования инвестиционных показателей по регионам России на несколько лет вперёд.  
Модель использует архитектуру Transformer для извлечения контекстных представлений временных рядов и отдельный авто-регрессивный декодер, который пошагово генерирует прогноз на заданный горизонт.

Модель поддерживает:
- синусоидальные и обучаемые позиционные кодировки,
- региональные эмбеддинги,
- несколько стратегий пуллинга контекста,
- teacher forcing,
- устойчивое обучение за счёт Huber loss, dropout, шума на входе и gradient clipping,
- интеграцию с Optuna для подбора гиперпараметров.

---

## Архитектура

### Входные данные

Входной тензор `x` имеет размер:

- `[batch_size, seq_len, n_features]`

где:
- `seq_len` — длина исторического окна,
- `n_features` — количество признаков на временной шаг.

### Региональные эмбеддинги (опционально)

Если `region_emb_size > 0`, используется слой `nn.Embedding`, который кодирует регион в плотный вектор.  
Региональный эмбеддинг конкатенируется с входными признаками **на каждом временном шаге**.

Это позволяет модели учитывать устойчивые структурные различия между регионами (экономика, демография, инфраструктура и т.д.).

---

### Проекция входа

После объединения признаков используется линейная проекция:

- `Linear(n_features + region_emb_size → d_model)`

Она приводит вход к размерности `d_model`, используемой внутри Transformer.

Дополнительно могут применяться:
- dropout на входе (`input_dropout`),
- гауссов шум (`input_noise_std`) во время обучения.

---

### Позиционное кодирование

Используется модуль `PositionalEncodingFlexible`, поддерживающий два режима:

- `sin` — классическое синусоидальное позиционное кодирование,
- `learned` — обучаемые позиционные эмбеддинги.

Позиционное кодирование добавляется к входным эмбеддингам перед подачей в Transformer Encoder.

---

### Transformer Encoder

Энкодер построен на `nn.TransformerEncoder` и состоит из:

- `num_layers` Encoder-блоков,
- multi-head self-attention (`nhead`),
- feed-forward слоёв размерности `dim_feedforward`,
- residual connections и LayerNorm.

Энкодер обрабатывает всю временную последовательность и возвращает тензор:

- `[batch_size, seq_len, d_model]`

---

### Пуллинг контекста

Для перехода от последовательности к фиксированному контекстному вектору используется один из вариантов пуллинга:

#### `last_mean`
Конкатенация:
- последнего временного шага энкодера,
- среднего значения по временной оси.

#### `attn`
Обучаемый attention-пуллинг:
- вычисляются веса внимания по временным шагам,
- формируется взвешенная сумма выходов энкодера,
- результат конкатенируется с последним шагом.

Итоговый контекст имеет размер:
- `ctx_dim = 2 * d_model`

Опционально применяется `LayerNorm`.

---

## Авто-регрессивный декодер

Декодер реализован как **пошаговый MLP**, а не Transformer Decoder.

### Инициализация

Первое значение (`prev`) определяется:
- либо через `start_proj(ctx)`,
- либо через `y_last`, если передано последнее реальное значение.

---

### Embedding шага прогноза

Для каждого шага горизонта используется embedding номера шага:

- `nn.Embedding(horizon, step_emb_dim)`

Это позволяет декодеру различать ранние и дальние прогнозы.

---

### Один шаг декодера

На каждом шаге `t` формируется вход:

- `[ctx, prev, step_embedding(t)]`

Далее применяется:
- Linear → GELU → Dropout → LayerNorm → Linear

На выходе получается одно скалярное значение прогноза.

---

### Auto-regressive loop

Прогноз строится последовательно:
- выход шага `t` используется как вход `prev` для шага `t+1`,
- поддерживается teacher forcing с вероятностью `teacher_forcing_prob`.

Выход модели:
- `[batch_size, horizon]`

---

## Инициализация весов

Используется единый подход:

- `Linear` — Xavier Uniform
- `LayerNorm` — веса = 1, bias = 0
- `Embedding` — Normal(mean=0, std=0.02)

---

## Основные гиперпараметры

| Параметр | Описание |
|--------|---------|
| n_features | Количество входных признаков |
| horizon | Длина горизонта прогноза |
| d_model | Размерность внутреннего представления |
| nhead | Количество голов self-attention |
| num_layers | Число слоёв Transformer Encoder |
| dim_feedforward | Размер FFN в Encoder |
| dropout | Dropout в Encoder и Decoder |
| pos_type | Тип позиционного кодирования (`sin`, `learned`) |
| pool_type | Тип пуллинга контекста |
| region_emb_size | Размер регионального эмбеддинга |
| input_dropout | Dropout на входе |
| input_noise_std | Шум на входе |
| teacher_forcing_prob | Вероятность teacher forcing |
| grad_clip | Усечение градиентов |

---

## Обучение

Обучение модели поддерживает:

- Оптимизаторы: Adam, AdamW, RMSProp
- Функции потерь: MSE, MAE, Huber
- LR Scheduler: StepLR, CosineAnnealing, OneCycle
- Gradient clipping
- Mixed Precision (AMP)
- Early stopping
- Полную интеграцию с Optuna

Валидация производится на полном горизонте прогноза.

---

## Особенности модели

- Transformer эффективно захватывает долгосрочные зависимости.
- Отдельный AR-декодер стабилен и проще классического Transformer Decoder.
- Региональные эмбеддинги повышают качество пространственных прогнозов.
- Step embeddings помогают разделять ближний и дальний прогноз.
- Архитектура хорошо подходит для долгосрочного экономического прогнозирования.
- Гибко масштабируется под различные размеры данных и горизонты.

---
