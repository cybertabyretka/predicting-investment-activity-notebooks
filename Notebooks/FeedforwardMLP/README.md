# FeedForwardAR

## Описание

**FeedForwardAR** — это полносвязная нейронная сеть (Feed-Forward Neural Network) для предсказания инвестиционных показателей по регионам России на основе исторических временных рядов.  
Модель работает как авто-регрессивная (AR), используя значения нескольких предыдущих временных шагов для предсказания будущих значений.

---

## Архитектура

Основные характеристики модели:

- **Входные данные**:  
  Входной тензор `x` имеет размер `[batch_size, seq_len, n_features]`, где:
  - `seq_len` — длина временного окна (количество прошлых шагов для анализа),
  - `n_features` — количество признаков на каждый шаг.

- **Региональные эмбеддинги (опционально)**:  
  Если задан `region_emb_size > 0`, используется слой `nn.Embedding` для кодирования регионов в вектор фиксированной размерности.  
  Эти эмбеддинги конкатенируются с временными признаками перед подачей в сеть.

- **Полносвязные слои (Feed-Forward)**:  
  Сеть состоит из последовательности слоев `Linear -> ReLU -> Dropout`. Размеры скрытых слоев задаются через параметр `hidden_sizes`.

- **Выходной слой**:  
  Линейный слой, выдающий предсказания на `horizon` будущих шагов.

- **Инициализация весов**:  
  Используется метод **Xavier Uniform** для весов и нули для смещений.

---

## Использование

Пример создания модели и проверки количества параметров:

```python
import torch
from torch import nn
from torch.nn import init

# Создание модели
test_model = FeedForwardAR(n_features=78, seq_len=4, horizon=3)
print(test_model)

# Подсчет параметров
total_params = sum(p.numel() for p in test_model.parameters())
trainable_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)

print(f"Total parameters: {total_params}")
print(f"Trainable parameters: {trainable_params}")
```
---

## Настройки гиперпараметров

Модель поддерживает следующие основные параметры:

| Параметр | Описание |
|----------|----------|
| `n_features` | Количество признаков на шаг |
| `seq_len` | Длина временного окна |
| `horizon` | Количество шагов для предсказания |
| `hidden_sizes` | Размеры скрытых слоев |
| `dropout` | Доля отключаемых нейронов |
| `region_emb_size` | Размер регионального эмбеддинга |

---

## Обучение

Обучение модели реализуется с помощью стандартного цикла PyTorch, с возможностью настройки:

- Оптимизатора (`Adam`, `AdamW`, `RMSProp`)
- Темпа обучения (`lr`)
- L2-регуляризации (`weight_decay`)
- Дропаут
- Усечения градиентов (`grad_clip`)
- Типа функции потерь: `MSE`, `MAE`, `Huber`

---

## Особенности

- Простая и быстрая в обучении архитектура.
- Подходит для небольших временных рядов.
- Поддержка региональных эмбеддингов.
- Легко интегрируется с автоматизированными процедурами подбора гиперпараметров (например, Optuna).

---
